{
    "model": "meta-llama/Llama-3.2-3B",
    "epochs": 1,
    "val_interval": 1,
    "lr": 0.0003,
    "batch_size": 64,
    "accumulation_steps": 16,
    "wandb": true,
    "task": "eval",
    "training": "combined",
    "verbose": true,
    "parallel": false,
    "quantization": true,
    "random_split": -1,
    "checkpoint": "epoch-4-all_Llama-3.2-3B"
}
